# üì¶ Recommendation System ‚Äî First Iteration (Embedding + MLP Hybrid Recommender)

*A PyTorch-based implicit-feedback recommendation system (first working prototype)*

This project implements the **first complete working version** of a neural recommendation system using **PyTorch**, **custom datasets**, and a **hybrid collaborative-filtering architecture**.
The aim of this iteration is to produce a clean, reproducible, end-to-end pipeline that loads user‚Äìitem interactions ‚Üí builds index mappings ‚Üí trains a hybrid neural model ‚Üí evaluates performance on validation data.

This version forms the **baseline recommender system** that your team can iterate on with more advanced architectures (attention, transformers, sequence modeling, etc.).

---

# üöÄ Project Overview

This repository contains:

* A single Python script: **`RecSys.py`**
* A **custom PyTorch Dataset** for user‚Äìitem interactions
* An **embedding-based recommender model** combining:

  * Dot-product similarity
  * A Multi-Layer Perceptron (Deep Component)
* A full **training loop**
* A **validation loop** with accuracy metrics
* Automatic **ID encoding** + preprocessing

This prototype establishes a clear and modular foundation for future improvements.

---

# üìÅ File Structure

```
RecSys.py
train.csv
val.csv
```

> Your script expects interaction CSV files with at least:
> `userId, itemId, target`

---

# üîß Main Components & Explanation (Step-by-Step Summary)

Below is a structured explanation of what **your script actually does**, following the same style as the example README.

---

# 1Ô∏è‚É£ Imports & Initial Setup

The script imports:

* `pandas`, `numpy` ‚Äî tabular data handling
* `torch`, `nn`, `DataLoader` ‚Äî model training + batching
* `tqdm` ‚Äî training progress bar
* `os` ‚Äî file paths
* `math` ‚Äî utilities

It automatically detects **CPU/GPU** and sets the device:

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

This allows training without any manual hardware configuration.

---

# 2Ô∏è‚É£ Loading the Data

The script reads:

```python
train.csv
val.csv
```

Each CSV requires the columns:

| Column | Description                           |
| ------ | ------------------------------------- |
| userId | Raw user ID from the dataset          |
| itemId | Raw item ID                           |
| target | Implicit label: 0/1 or click/no-click |

The system **does not** rely on timestamp order ‚Äî this version implements a **pointwise implicit recommender**, not a sequential one.

---

# 3Ô∏è‚É£ User/Item Encoding

To use embedding layers, the model needs **dense, continuous indices**.

The script scans the dataset to build two mappings:

```
raw_user_id ‚Üí internal_user_index
raw_item_id ‚Üí internal_item_index
```

Why?

* Embeddings require IDs starting at 0
* Memory remains compact
* Training is faster and stable

The mappings are stored inside the dataset class and used throughout training.

---

# 4Ô∏è‚É£ Custom PyTorch Dataset

The core dataset class is:

```python
class RecSysDataset(torch.utils.data.Dataset)
```

It returns a tuple for each training sample:

```
(user_idx, item_idx, target)
```

All values are converted to PyTorch tensors.

This forms the backbone of the training pipeline, ensuring:

* Efficient batching
* GPU-optimized data loading
* Clean separation of data and model logic

---

# 5Ô∏è‚É£ DataLoader Setup

Next, the script constructs:

```python
train_loader = DataLoader(...)
val_loader   = DataLoader(...)
```

With batching, shuffling (for training), and correct tensor formatting.

This enables:

* Mini-batch gradient descent
* Batched predictions
* Faster GPU utilization

---

# 6Ô∏è‚É£ Recommender Model Architecture (Your Hybrid Design)

The script defines a hybrid recommender:

```python
class HybridRecSys(nn.Module)
```

It combines two core ideas:

## ‚úî A. Embedding-Based Collaborative Filtering

Two embedding layers:

```python
user_embedding = Embedding(num_users, embed_dim)
item_embedding = Embedding(num_items, embed_dim)
```

Purpose:

* Learn latent user preferences
* Learn latent item attributes
* Capture collaborative patterns

---

## ‚úî B. A Deep MLP Interaction Component

After embeddings are extracted, they are concatenated:

```
[ user_embed || item_embed ]
```

Then passed through an MLP with:

* Linear layers
* ReLU activation
* Optional dropout

This component learns nonlinear patterns such as:

* ‚ÄúUsers who like A and B also like C only when item metadata is similar‚Äù
* Complex interaction relationships not captured by dot-product alone

---

## ‚úî C. Dot Product Similarity Component

Parallel to the MLP, the script computes:

```
score = dot(user_embedding, item_embedding)
```

This is the classical Matrix Factorization relevance measure.

It provides:

* Stable gradients
* Good cold-start generalization
* Strong baseline performance

---

## ‚úî D. Final Output = Deep Score + Dot Score

The final predicted logit is:

```
output = mlp_score + dot_score
```

This hybrid scoring mechanism is used in many production recommenders (YouTube, Amazon, TikTok).

---

# 7Ô∏è‚É£ Training Pipeline

The training loop performs:

1. Forward pass
2. Compute **BCEWithLogitsLoss** (more stable than BCE)
3. Backpropagation
4. Update weights with Adam optimizer
5. Track moving averages of:

   * Loss
   * Accuracy
   * Throughput (samples/sec)

The script prints clean training logs per epoch.

---

# 8Ô∏è‚É£ Validation Pipeline

After each epoch:

* Model is put in `eval()` mode
* Gradients disabled (`torch.no_grad()`)
* Validation loss
* Validation accuracy

This allows detection of:

* Overfitting
* Underfitting
* Training inconsistencies

---

# üß† Model Summary

| Component      | Description                      |
| -------------- | -------------------------------- |
| User Embedding | `num_users √ó embed_dim`          |
| Item Embedding | `num_items √ó embed_dim`          |
| MLP Layers     | Nonlinear user‚Äìitem interactions |
| Dot Product    | Classic collaborative filtering  |
| Loss Function  | BCEWithLogitsLoss                |
| Optimizer      | Adam                             |
| Hardware       | GPU if available                 |

---

# ‚ñ∂Ô∏è How to Run the Project

### 1. Install dependencies:

```
pip install torch pandas numpy tqdm
```

### 2. Prepare the CSV files:

They must include:

```
userId, itemId, target
```

### 3. Run the script:

```
python RecSys.py
```

